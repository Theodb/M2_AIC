{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Kaggle challenge : https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Tutorial : Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "# %matplotlib inline  \n",
    "import pandas as pd #for manipulating data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titanic_data():\n",
    "     \n",
    "    np.random.seed(42)\n",
    "    # get titanic & test csv files as a DataFrame\n",
    "    titanic_df = pd.read_csv(\"tp4-train_titanic.csv\", dtype={\"Age\": np.float64}, )\n",
    "\n",
    "    # drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
    "    titanic_df = titanic_df.drop(['PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch' , 'Fare', 'Cabin'], axis=1)\n",
    "\n",
    "\n",
    "    # only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n",
    "    titanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "    # Age: values are missing, we replace them\n",
    "    # get average, std, and number of NaN values in titanic_df\n",
    "    average_age_titanic   = titanic_df[\"Age\"].mean()\n",
    "    std_age_titanic       = titanic_df[\"Age\"].std()\n",
    "    count_nan_age_titanic = titanic_df[\"Age\"].isnull().sum()\n",
    "    # generate random numbers between (mean - std) & (mean + std)\n",
    "    rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n",
    "    titanic_df['Age'].dropna().astype(int)\n",
    "    # fill NaN values in Age column with random values generated   \n",
    "    titanic_df[\"Age\"] = titanic_df[\"Age\"].fillna(30)\n",
    "    # convert from float to int\n",
    "    titanic_df['Age'] = titanic_df['Age'].astype(int)\n",
    "    \n",
    "    # y contains the information we try to predit: did the passenger survive ?\n",
    "    y = titanic_df['Survived']\n",
    "    \n",
    "    # X contains useful data for classification\n",
    "    X = titanic_df.drop( [\"Survived\"], axis = 1)\n",
    "    print(\"X: données:\")\n",
    "    print(X.head())\n",
    "   \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: données:\n",
      "   Pclass     Sex  Age Embarked\n",
      "0       3    male   22        S\n",
      "1       1  female   38        C\n",
      "2       3  female   26        S\n",
      "3       1  female   35        S\n",
      "4       3    male   35        S\n",
      "\n",
      "\n",
      "[22 38 26 35 35]\n",
      "['male' 'female' 'female' 'female' 'male']\n",
      "[0 1 1 1 0]\n",
      "[False  True False False False]\n",
      "[False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "X, y = get_titanic_data()\n",
    "\"\"\"\n",
    "We access data using the name of the features as attributes of X:\n",
    "X.Pclass, X.Sex, X.age, X.Embarked , or equivalently:  X[\"Pclass\"], X[\"Sex\"], etc...\n",
    "We can also turn them into lists or vectors (arrays) :\n",
    "\"\"\"\n",
    "print(\"\\n\")\n",
    "print(np.array(X[\"Age\"])[:5])\n",
    "print(np.array(X[\"Sex\"])[:5])\n",
    "print(np.array(y)[:5])\n",
    "\"\"\"\n",
    "This makes data extraction easy:\n",
    "\"\"\"\n",
    "print(np.array((X['Age'] == 38)&(X['Sex'] == 'female'))[:5]) \n",
    "print(np.array((X['Age'] < 30)&(y == 1))[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercices : \n",
    "\n",
    "1. Exploration :\n",
    "    - Print the rate of survival, as a function of gender (i.e. prob(Survive | gender = female) et proba(Survive | gender = male)). \n",
    "    - Likewise for the class (1st class being morre expensive) and Boarding harbor (1 = Cherbourg; 2 = Queenstown; 3 = Southampton).\n",
    "    - Which feature seems most informative ?\n",
    "    - How could we apply this idea to age ? \n",
    "    \n",
    "    \n",
    "2. Analysis :\n",
    "    - Code the entropy function, for a Bernoulli variable, as a function of its parameter $p$. Plot it.        \n",
    "    - Compute the information gain $I$ provided by the gender variable.\n",
    "    - Likewise for class and bording harbor.\n",
    "    - Which factor effectively yields most information ?\n",
    "    - Same question with age ranges ?\n",
    "    - How to explain this advantage ? What is the inconvenient ?\n",
    "\n",
    "\n",
    "3. Model and prediction:\n",
    "    - For *tree.DecisionTreeClassifier()*, we need data to be numerical. Digitize the text data to match this expected input form. You should drop one feature (the least informative one).\n",
    "    - Using *tree.DecisionTreeClassifier()* (from *sklearn*), train a decision tree.\n",
    "    - Does the attribute *feature_importances* of *tree.DecisionTreeClassifier()* produce the same results as your hand-written analysis ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survival probability as a function of gender, boarding harbor, or ticket class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Entropy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-5-84db7efdb265>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-84db7efdb265>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    list_p = np.arange(0.00,1.01,0.01)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "with p = Prob(survived | gender = female) \n",
    "I(gender) = -p * log(p) - (1-p) * log(1- p)\n",
    "Recall: a lower-I variable is more informative than a large one.\n",
    "\"\"\"\n",
    "\n",
    "def entropy(p):\n",
    "    #TODO\n",
    "    \n",
    "list_p = np.arange(0.00,1.01,0.01)\n",
    "plt.plot(list_p, [entropy(p) for p in list_p])\n",
    "\n",
    "plt.title('Entropy function')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('uncertainty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
