{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to see next ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other learning model\n",
    "\n",
    "- Recurrent model\n",
    "\n",
    "    - RNN : https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html \n",
    "\n",
    "    - LSTM : https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "\n",
    "    - GRU\n",
    "\n",
    "- Reinforcement learning : https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modality\n",
    "\n",
    "- torchvision : https://pytorch.org/docs/master/torchvision/index.html#module-torchvision\n",
    "    - datasets\n",
    "    - trained models\n",
    "    - transform functions\n",
    "    \n",
    "    \n",
    "- torchaudio : https://pytorch.org/audio/\n",
    "    - datasets\n",
    "    - audio processing functions\n",
    "    - transform functions\n",
    "    \n",
    "    \n",
    "- torchtext : https://torchtext.readthedocs.io/en/latest/\n",
    "    - datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from PyTorch model format to ONNX (Open Neural Network eXchange format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open format to represent deep learning models.\n",
    "- Framework Interoperability : Move models between state-of-the-art tools and choose the best.\n",
    "- Hardware optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%actual_input_1 : Float(10, 3, 224, 224)\n",
      "      %learned_0 : Float(64, 3, 11, 11)\n",
      "      %learned_1 : Float(64)\n",
      "      %learned_2 : Float(192, 64, 5, 5)\n",
      "      %learned_3 : Float(192)\n",
      "      %learned_4 : Float(384, 192, 3, 3)\n",
      "      %learned_5 : Float(384)\n",
      "      %learned_6 : Float(256, 384, 3, 3)\n",
      "      %learned_7 : Float(256)\n",
      "      %learned_8 : Float(256, 256, 3, 3)\n",
      "      %learned_9 : Float(256)\n",
      "      %learned_10 : Float(4096, 9216)\n",
      "      %learned_11 : Float(4096)\n",
      "      %learned_12 : Float(4096, 4096)\n",
      "      %learned_13 : Float(4096)\n",
      "      %learned_14 : Float(1000, 4096)\n",
      "      %learned_15 : Float(1000)) {\n",
      "  %17 : Float(10, 64, 55, 55) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%actual_input_1, %learned_0, %learned_1), scope: AlexNet/Sequential[features]/Conv2d[0]\n",
      "  %18 : Float(10, 64, 55, 55) = onnx::Relu(%17), scope: AlexNet/Sequential[features]/ReLU[1]\n",
      "  %19 : Float(10, 64, 27, 27) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18), scope: AlexNet/Sequential[features]/MaxPool2d[2]\n",
      "  %20 : Float(10, 192, 27, 27) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%19, %learned_2, %learned_3), scope: AlexNet/Sequential[features]/Conv2d[3]\n",
      "  %21 : Float(10, 192, 27, 27) = onnx::Relu(%20), scope: AlexNet/Sequential[features]/ReLU[4]\n",
      "  %22 : Float(10, 192, 13, 13) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%21), scope: AlexNet/Sequential[features]/MaxPool2d[5]\n",
      "  %23 : Float(10, 384, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %learned_4, %learned_5), scope: AlexNet/Sequential[features]/Conv2d[6]\n",
      "  %24 : Float(10, 384, 13, 13) = onnx::Relu(%23), scope: AlexNet/Sequential[features]/ReLU[7]\n",
      "  %25 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %learned_6, %learned_7), scope: AlexNet/Sequential[features]/Conv2d[8]\n",
      "  %26 : Float(10, 256, 13, 13) = onnx::Relu(%25), scope: AlexNet/Sequential[features]/ReLU[9]\n",
      "  %27 : Float(10, 256, 13, 13) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%26, %learned_8, %learned_9), scope: AlexNet/Sequential[features]/Conv2d[10]\n",
      "  %28 : Float(10, 256, 13, 13) = onnx::Relu(%27), scope: AlexNet/Sequential[features]/ReLU[11]\n",
      "  %29 : Float(10, 256, 6, 6) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28), scope: AlexNet/Sequential[features]/MaxPool2d[12]\n",
      "  %30 : Long() = onnx::Constant[value={0}](), scope: AlexNet\n",
      "  %31 : Tensor = onnx::Shape(%29), scope: AlexNet\n",
      "  %32 : Long() = onnx::Gather[axis=0](%31, %30), scope: AlexNet\n",
      "  %33 : Long() = onnx::Constant[value={9216}](), scope: AlexNet\n",
      "  %34 : Tensor = onnx::Unsqueeze[axes=[0]](%32)\n",
      "  %35 : Tensor = onnx::Unsqueeze[axes=[0]](%33)\n",
      "  %36 : Tensor = onnx::Concat[axis=0](%34, %35)\n",
      "  %37 : Float(10, 9216) = onnx::Reshape(%29, %36), scope: AlexNet\n",
      "  %38 : Float(10, 9216), %39 : Tensor = onnx::Dropout[ratio=0.5](%37), scope: AlexNet/Sequential[classifier]/Dropout[0]\n",
      "  %40 : Float(10, 4096) = onnx::Gemm[alpha=1, beta=1, transB=1](%38, %learned_10, %learned_11), scope: AlexNet/Sequential[classifier]/Dropout[0]\n",
      "  %41 : Float(10, 4096) = onnx::Relu(%40), scope: AlexNet/Sequential[classifier]/ReLU[2]\n",
      "  %42 : Float(10, 4096), %43 : Tensor = onnx::Dropout[ratio=0.5](%41), scope: AlexNet/Sequential[classifier]/Dropout[3]\n",
      "  %44 : Float(10, 4096) = onnx::Gemm[alpha=1, beta=1, transB=1](%42, %learned_12, %learned_13), scope: AlexNet/Sequential[classifier]/Dropout[3]\n",
      "  %45 : Float(10, 4096) = onnx::Relu(%44), scope: AlexNet/Sequential[classifier]/ReLU[5]\n",
      "  %output1 : Float(10, 1000) = onnx::Gemm[alpha=1, beta=1, transB=1](%45, %learned_14, %learned_15), scope: AlexNet/Sequential[classifier]/ReLU[5]\n",
      "  return (%output1);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "dummy_input = torch.randn(10, 3, 224, 224)\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install ONNX\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge onnx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ONNX model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"alexnet.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "onnx.helper.printable_graph(model.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
