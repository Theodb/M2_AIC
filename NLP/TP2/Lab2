TP2 - Deschamps-Berger Théo / Warichet Sebastien

Questions

Q1 Testez les performances de l’annotation en entités nommées avec un fichier de patron de base (comme celui-ci).

Les performances du modèle généré sont les suivantes :
 Token error   :  6.61%
 Sequence error: 42.37%

42.37% d'erreurs par phrase.

Q2 Modifiez le fichier de patrons afin d’obtenir les meilleures performances possibles.
   -ajoutez par exemple l’étiquette morpho-syntaxique si vous travaillez sur l’anglais
   -ajoutez des expressions régulières (mot commençant par une majuscule, entièrement en majuscule…)

Après l'ajout de l'étiquette morpho-syntaxique au fichier patron,
 u6:%x[-2,1]
 u7:%x[-1,1]
 u8:%x[0,1]
 u9:%x[1,1]
 u10:%x[2,1]

nous obtenons le taux d'erreur suivant :
 Token error   :  5.01%
 Sequence error: 36.18%

Puis l'ajout d'une feature qui teste si notre mot commence ou non par une majuscule et nous renvoit un résultat booléen.
 u13:%t[0,0,"^\u"]

Nous donne le taux d'erreur suivant :
 Token error   :  4.62%
 Sequence error: 33.06%

Et finalement l'ajout d'une dernière feature qui teste si notre mot est composé uniquement de majuscule.
 u14:%t[0,0,"^\u*$"]

Nous donne le taux d'erreur de:
 Token error   :  4.47%
 Sequence error: 32.52%


Q3    Enrichissez les corpus avec des ressources extérieures: catégories morphosyntaxiques venant d’un autre étiqueteur, listes d’entités ou de déclencheurs (M./Mme)…
        utilisation de l’étiquetage de nltk ou de Stanford CoreNLP
        Vous pouvez vous inspirer d’articles récents du domaine: http://www.anthology.aclweb.org/I/I11/I11-1142.pdf, http://www.aclweb.org/anthology/F14-3014, https://noisy-text.github.io/pdf/WNUT09.pdf

Nous avons du retransformer le corpus en un texte pour pouvoir l'utiliser avec StanfordCoreNLP sous python.



Q4  Comparez vos résultats avec ceux de nltk ou de Stanford CoreNLP

