{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Create a context, contex are used to work with RDD\n",
    "# Spark URL is local application name is TP1\n",
    "sc = SparkContext(\"local\", \"TP1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open text file, lines is a RDD\n",
    "lines = sc.textFile(\"lai-eliduc.txt\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_count = lines.count()\n",
    "lines_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tupple (line, lenght) (Lazzy: map is not computed yet)\n",
    "lineLengths = lines.map(lambda s: len(s))\n",
    "# add all lines lenght (map and reduce are computed because reduce is an action)\n",
    "totalLength = lineLengths.reduce(lambda a, b: a + b)\n",
    "totalLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['De',\n",
       " 'un',\n",
       " 'mut',\n",
       " 'ancïen',\n",
       " 'lai',\n",
       " 'bretun',\n",
       " 'Le',\n",
       " 'cunte',\n",
       " 'e',\n",
       " 'tute',\n",
       " 'la',\n",
       " 'reisun',\n",
       " 'Vus',\n",
       " 'dirai,',\n",
       " 'si',\n",
       " 'cum',\n",
       " 'jeo',\n",
       " 'entent',\n",
       " 'La',\n",
       " 'verité,',\n",
       " 'mun',\n",
       " 'escïent.',\n",
       " 'En',\n",
       " 'Britaine',\n",
       " 'ot',\n",
       " 'un',\n",
       " 'chevalier',\n",
       " 'Pruz',\n",
       " 'e',\n",
       " 'curteis,',\n",
       " 'hardi',\n",
       " 'e',\n",
       " 'fier',\n",
       " ';',\n",
       " 'Elidus',\n",
       " 'ot',\n",
       " 'nun,',\n",
       " 'ceo',\n",
       " \"m'est\",\n",
       " 'vis,',\n",
       " \"N'ot\",\n",
       " 'si',\n",
       " 'vaillant',\n",
       " 'hume',\n",
       " 'al',\n",
       " 'païs.',\n",
       " 'Femme',\n",
       " 'ot',\n",
       " 'espuse,',\n",
       " 'noble',\n",
       " 'e',\n",
       " 'sage,',\n",
       " 'De',\n",
       " 'haute',\n",
       " 'gent,',\n",
       " 'de',\n",
       " 'grant',\n",
       " 'parage.',\n",
       " 'E',\n",
       " 'vit',\n",
       " 'le',\n",
       " 'lit',\n",
       " 'a',\n",
       " 'la',\n",
       " 'pucele,',\n",
       " 'Mut',\n",
       " \"s'entr'amerent\",\n",
       " 'lëaument',\n",
       " ';',\n",
       " 'Mes',\n",
       " 'puis',\n",
       " 'avient',\n",
       " 'par',\n",
       " 'une',\n",
       " 'guere',\n",
       " 'Quë',\n",
       " 'il',\n",
       " 'alat',\n",
       " 'soudees',\n",
       " 'quere',\n",
       " ':',\n",
       " 'Iloc',\n",
       " 'ama',\n",
       " 'une',\n",
       " 'meschine,',\n",
       " 'Fille',\n",
       " 'ert',\n",
       " 'a',\n",
       " 'rei',\n",
       " 'e',\n",
       " 'a',\n",
       " 'reïne.',\n",
       " 'Guilliadun',\n",
       " 'ot',\n",
       " 'nun',\n",
       " 'la',\n",
       " 'pucele,',\n",
       " 'El',\n",
       " 'rëaume',\n",
       " 'nen',\n",
       " 'ot',\n",
       " 'plus',\n",
       " 'bele.',\n",
       " 'La',\n",
       " 'femme',\n",
       " 'resteit',\n",
       " 'apelee',\n",
       " 'Guildelüec',\n",
       " 'en',\n",
       " 'sa',\n",
       " 'cuntree.',\n",
       " \"D'eles\",\n",
       " 'deus',\n",
       " 'ad',\n",
       " 'li',\n",
       " 'lai',\n",
       " 'a',\n",
       " 'nun',\n",
       " 'Guildelüec',\n",
       " 'ha',\n",
       " 'Gualadun.',\n",
       " 'Elidus',\n",
       " 'fu',\n",
       " 'primes',\n",
       " 'nomez,',\n",
       " 'Mes',\n",
       " 'ore',\n",
       " 'est',\n",
       " 'li',\n",
       " 'nuns',\n",
       " 'remüez,',\n",
       " 'Kar',\n",
       " 'des',\n",
       " 'dames',\n",
       " 'est',\n",
       " 'avenue.',\n",
       " \"L'aventure\",\n",
       " 'dunt',\n",
       " 'li',\n",
       " 'lais',\n",
       " 'fu,',\n",
       " 'Si',\n",
       " 'cum',\n",
       " 'avient,',\n",
       " 'vus',\n",
       " 'cunterai,',\n",
       " 'La',\n",
       " 'verité',\n",
       " 'vus',\n",
       " 'en',\n",
       " 'dirrai.',\n",
       " '',\n",
       " 'Elidus',\n",
       " 'aveit',\n",
       " 'un',\n",
       " 'seignur,',\n",
       " 'Reis',\n",
       " 'de',\n",
       " 'Brutaine',\n",
       " 'la',\n",
       " 'meinur,',\n",
       " 'Que',\n",
       " 'mut',\n",
       " \"l'amot\",\n",
       " 'e',\n",
       " 'cherisseit,',\n",
       " 'E',\n",
       " 'il',\n",
       " 'lëaument',\n",
       " 'le',\n",
       " 'serveit.',\n",
       " 'U',\n",
       " 'que',\n",
       " 'li',\n",
       " 'reis',\n",
       " 'deüst',\n",
       " 'errer,',\n",
       " 'Il',\n",
       " 'aveit',\n",
       " 'la',\n",
       " 'tere',\n",
       " 'a',\n",
       " 'garder;',\n",
       " 'Pur',\n",
       " 'sa',\n",
       " 'prüesce',\n",
       " 'le',\n",
       " 'retint.',\n",
       " 'Pur',\n",
       " 'tant',\n",
       " 'de',\n",
       " 'meuz',\n",
       " 'mut',\n",
       " 'li',\n",
       " 'avint',\n",
       " ':',\n",
       " 'Par',\n",
       " 'les',\n",
       " 'forez',\n",
       " 'poeit',\n",
       " 'chacier',\n",
       " ';',\n",
       " \"N'i\",\n",
       " 'ot',\n",
       " 'si',\n",
       " 'hardi',\n",
       " 'forestier',\n",
       " 'Ki',\n",
       " 'cuntredire',\n",
       " 'li',\n",
       " 'osast',\n",
       " 'Ne',\n",
       " 'ja',\n",
       " 'une',\n",
       " 'feiz',\n",
       " 'en',\n",
       " 'grusçast.',\n",
       " 'Pur',\n",
       " \"l'envie\",\n",
       " 'del',\n",
       " 'bien',\n",
       " 'de',\n",
       " 'lui,',\n",
       " 'Si',\n",
       " 'cum',\n",
       " 'avient',\n",
       " 'sovent',\n",
       " \"d'autrui,\",\n",
       " 'Esteit',\n",
       " 'a',\n",
       " 'sun',\n",
       " 'seignur',\n",
       " 'medlez',\n",
       " '(e)',\n",
       " 'Empeirez',\n",
       " 'e',\n",
       " 'encusez,',\n",
       " 'Que',\n",
       " 'de',\n",
       " 'la',\n",
       " 'curt',\n",
       " 'le',\n",
       " 'cungea',\n",
       " 'Sanz',\n",
       " 'ceo',\n",
       " \"qu'il\",\n",
       " 'ne',\n",
       " \"l'areisuna.\",\n",
       " 'Eliducs',\n",
       " 'ne',\n",
       " 'saveit',\n",
       " 'pur',\n",
       " 'quei.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Soventefiez',\n",
       " 'requist',\n",
       " 'le',\n",
       " 'rei',\n",
       " \"Qu'il\",\n",
       " 'excundist',\n",
       " 'de',\n",
       " 'lui',\n",
       " 'preïst',\n",
       " 'E',\n",
       " 'que',\n",
       " 'losenge',\n",
       " 'ne',\n",
       " 'creïst,',\n",
       " 'Mut',\n",
       " \"l'aveit\",\n",
       " 'volenters',\n",
       " 'servi',\n",
       " ';',\n",
       " 'Mes',\n",
       " 'li',\n",
       " 'rei',\n",
       " 'ne',\n",
       " 'li',\n",
       " 'respundi.',\n",
       " 'Quant',\n",
       " 'il',\n",
       " 'nel',\n",
       " 'volt',\n",
       " 'de',\n",
       " 'rien',\n",
       " 'oïr,',\n",
       " 'Si',\n",
       " \"l'en\",\n",
       " 'covient',\n",
       " 'idunc',\n",
       " 'partir.',\n",
       " 'A',\n",
       " 'sa',\n",
       " 'mesun',\n",
       " 'en',\n",
       " 'est',\n",
       " 'alez,',\n",
       " 'Si',\n",
       " 'ad',\n",
       " 'tuz',\n",
       " 'ses',\n",
       " 'amis',\n",
       " 'mandez;',\n",
       " 'Del',\n",
       " 'rei',\n",
       " 'sun',\n",
       " 'seignur',\n",
       " 'lur',\n",
       " 'mustra',\n",
       " 'E',\n",
       " 'de',\n",
       " \"l'ire\",\n",
       " 'que',\n",
       " 'vers',\n",
       " 'lui',\n",
       " 'a',\n",
       " ';',\n",
       " 'Mut',\n",
       " 'li',\n",
       " 'servi',\n",
       " 'a',\n",
       " 'sun',\n",
       " 'poeir,',\n",
       " 'Ja',\n",
       " 'ne',\n",
       " 'deüst',\n",
       " 'maugré',\n",
       " 'aveir.',\n",
       " 'Li',\n",
       " 'vileins',\n",
       " 'dit',\n",
       " 'par',\n",
       " 'reprover,',\n",
       " 'Quant',\n",
       " 'tencë',\n",
       " 'a',\n",
       " 'sun',\n",
       " 'charïer,',\n",
       " 'Que',\n",
       " 'amur',\n",
       " 'deeignur',\n",
       " \"n'est\",\n",
       " 'pas',\n",
       " 'fiez.',\n",
       " 'Sil',\n",
       " 'est',\n",
       " 'sages',\n",
       " 'e',\n",
       " 'vedzïez',\n",
       " 'Ki',\n",
       " 'lëauté',\n",
       " 'tient',\n",
       " 'sun',\n",
       " 'seignur,',\n",
       " 'Envers',\n",
       " 'ses',\n",
       " 'bons',\n",
       " 'veisins',\n",
       " 'amur.',\n",
       " 'Ne',\n",
       " 'volt',\n",
       " 'al',\n",
       " 'païs',\n",
       " 'arester,',\n",
       " 'Ainz',\n",
       " 'passera,',\n",
       " 'ceo',\n",
       " 'dit,',\n",
       " 'la',\n",
       " 'mer,',\n",
       " 'Al',\n",
       " 'rëaume',\n",
       " 'de',\n",
       " 'Loengre',\n",
       " 'ira,',\n",
       " 'Une',\n",
       " 'piece',\n",
       " 'se',\n",
       " 'deduira;',\n",
       " 'Sa',\n",
       " 'femme',\n",
       " 'en',\n",
       " 'la',\n",
       " 'tere',\n",
       " 'larra,',\n",
       " 'A',\n",
       " 'ses',\n",
       " 'hummes',\n",
       " 'cumandera',\n",
       " 'Quë',\n",
       " 'il',\n",
       " 'la',\n",
       " 'gardent',\n",
       " 'lëaument',\n",
       " 'E',\n",
       " 'tuit',\n",
       " 'si',\n",
       " 'ami',\n",
       " 'ensement.',\n",
       " 'A',\n",
       " 'cel',\n",
       " 'cunseil',\n",
       " \"s'est\",\n",
       " 'arestez,',\n",
       " 'Si',\n",
       " \"s'est\",\n",
       " 'richement',\n",
       " 'aturnez.',\n",
       " 'Mut',\n",
       " 'furent',\n",
       " 'dolent',\n",
       " 'si',\n",
       " 'ami',\n",
       " 'Pur',\n",
       " 'ceo',\n",
       " 'ke',\n",
       " 'de',\n",
       " 'eus',\n",
       " 'se',\n",
       " 'departi.',\n",
       " 'Dis',\n",
       " 'chevalers',\n",
       " 'od',\n",
       " 'sei',\n",
       " 'mena,',\n",
       " 'E',\n",
       " 'sa',\n",
       " 'femme',\n",
       " 'le',\n",
       " 'cunvea;',\n",
       " 'Forment',\n",
       " 'demeine',\n",
       " 'grant',\n",
       " 'dolur',\n",
       " 'Al',\n",
       " 'departie',\n",
       " '(de)',\n",
       " 'sun',\n",
       " 'seignur',\n",
       " ';',\n",
       " 'Mes',\n",
       " 'il',\n",
       " \"l'aseürat\",\n",
       " 'de',\n",
       " 'sei',\n",
       " \"Qu'il\",\n",
       " 'li',\n",
       " 'porterat',\n",
       " 'bone',\n",
       " 'fei.',\n",
       " 'De',\n",
       " 'lui',\n",
       " 'se',\n",
       " 'departi',\n",
       " 'atant,',\n",
       " 'Il',\n",
       " 'tient',\n",
       " 'sun',\n",
       " 'chemin',\n",
       " 'tut',\n",
       " 'avant',\n",
       " ';',\n",
       " 'A',\n",
       " 'la',\n",
       " 'mer',\n",
       " 'vient,',\n",
       " 'si',\n",
       " 'est',\n",
       " 'passez,',\n",
       " 'En',\n",
       " 'Toteneis',\n",
       " 'est',\n",
       " 'arivez.',\n",
       " 'Plusurs',\n",
       " 'reis',\n",
       " '(i)',\n",
       " 'ot',\n",
       " 'en',\n",
       " 'la',\n",
       " 'tere,',\n",
       " 'Entre',\n",
       " 'eus',\n",
       " 'eurent',\n",
       " 'estrif',\n",
       " 'e',\n",
       " 'guere.',\n",
       " 'Vers',\n",
       " 'Excestrë',\n",
       " 'en',\n",
       " 'cel',\n",
       " 'païs',\n",
       " 'Maneit',\n",
       " 'un',\n",
       " 'hum',\n",
       " 'mut',\n",
       " 'poëstis,',\n",
       " 'Vieuz',\n",
       " 'hum',\n",
       " 'e',\n",
       " 'auntïen',\n",
       " 'esteit.',\n",
       " '',\n",
       " 'Karnel',\n",
       " 'heir',\n",
       " 'madle',\n",
       " 'nen',\n",
       " 'aveit',\n",
       " ';',\n",
       " 'Une',\n",
       " 'fille',\n",
       " 'ot',\n",
       " 'a',\n",
       " 'merïer.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Pur',\n",
       " 'ceo',\n",
       " \"l'il\",\n",
       " 'ne',\n",
       " 'la',\n",
       " 'volt',\n",
       " 'doner',\n",
       " 'A',\n",
       " 'sun',\n",
       " 'per,',\n",
       " 'cil',\n",
       " 'le',\n",
       " 'guerriot,',\n",
       " 'Tute',\n",
       " 'sa',\n",
       " 'tere',\n",
       " 'si',\n",
       " 'gastot.',\n",
       " 'En',\n",
       " 'un',\n",
       " 'chastel',\n",
       " \"l'aveit\",\n",
       " 'enclos',\n",
       " ';',\n",
       " \"N'ot\",\n",
       " 'el',\n",
       " 'chastel',\n",
       " 'hume',\n",
       " 'si',\n",
       " 'os',\n",
       " 'Ki',\n",
       " 'cuntre',\n",
       " 'lui',\n",
       " 'osast',\n",
       " 'eissir',\n",
       " 'Estur',\n",
       " 'ne',\n",
       " 'mellee',\n",
       " 'tenir.',\n",
       " 'Elidus',\n",
       " 'en',\n",
       " 'oï',\n",
       " 'parler;',\n",
       " 'Ne',\n",
       " 'voleit',\n",
       " 'mes',\n",
       " 'a',\n",
       " 'vant',\n",
       " 'aler,',\n",
       " 'Quant',\n",
       " 'iloc',\n",
       " 'ad',\n",
       " 'guere',\n",
       " 'trovee',\n",
       " ';',\n",
       " 'Remaner',\n",
       " 'volt',\n",
       " 'en',\n",
       " 'la',\n",
       " 'cuntree.',\n",
       " 'Li',\n",
       " 'reis',\n",
       " 'ki',\n",
       " 'plus',\n",
       " 'esteit',\n",
       " 'grevez',\n",
       " 'E',\n",
       " 'damagiez',\n",
       " 'e',\n",
       " 'encumbrez',\n",
       " 'Vodrat',\n",
       " 'aider',\n",
       " 'a',\n",
       " 'sun',\n",
       " 'poeir',\n",
       " 'E',\n",
       " 'en',\n",
       " 'soudees',\n",
       " 'remaneir.',\n",
       " 'Ses',\n",
       " 'messages',\n",
       " 'i',\n",
       " 'enveia',\n",
       " 'E',\n",
       " 'par',\n",
       " 'ses',\n",
       " 'lettres',\n",
       " 'li',\n",
       " 'manda',\n",
       " 'Que',\n",
       " 'de',\n",
       " 'sun',\n",
       " 'païs',\n",
       " 'iert',\n",
       " 'eissuz',\n",
       " 'E',\n",
       " 'en',\n",
       " \"s'aïe\",\n",
       " 'esteit',\n",
       " 'venuz',\n",
       " ';',\n",
       " 'Mes',\n",
       " 'li',\n",
       " '(re)mandast',\n",
       " 'sun',\n",
       " 'pleisir,',\n",
       " 'E',\n",
       " \"s'il\",\n",
       " 'nel',\n",
       " 'voleit',\n",
       " 'retenir,',\n",
       " 'Cunduit',\n",
       " 'li',\n",
       " 'donast',\n",
       " 'par',\n",
       " 'sa',\n",
       " 'tere',\n",
       " ';',\n",
       " 'Avant',\n",
       " 'ireit',\n",
       " 'soudees',\n",
       " 'quere.',\n",
       " 'Quant',\n",
       " 'li',\n",
       " 'reis',\n",
       " 'vit',\n",
       " 'les',\n",
       " 'messagers,',\n",
       " 'Mut',\n",
       " 'les',\n",
       " 'ama',\n",
       " 'e',\n",
       " '(mut)',\n",
       " 'ot',\n",
       " 'chers',\n",
       " ';',\n",
       " 'Sun',\n",
       " 'cunestable',\n",
       " 'ad',\n",
       " 'apelez',\n",
       " 'E',\n",
       " 'hastivement',\n",
       " 'comandez',\n",
       " 'Que',\n",
       " 'cunduit',\n",
       " 'li',\n",
       " 'appareillast',\n",
       " '(e)',\n",
       " 'Ke',\n",
       " 'le',\n",
       " 'barun',\n",
       " 'amenast,',\n",
       " 'Si',\n",
       " 'face',\n",
       " 'osteus',\n",
       " 'appareiller',\n",
       " 'U',\n",
       " 'il',\n",
       " 'puïssent',\n",
       " 'herberger,',\n",
       " 'Tant',\n",
       " 'lur',\n",
       " 'face',\n",
       " 'livrer',\n",
       " 'e',\n",
       " 'rendre',\n",
       " 'Cum',\n",
       " 'il',\n",
       " 'codrunt',\n",
       " 'le',\n",
       " 'meis',\n",
       " 'despendre.',\n",
       " 'Li',\n",
       " 'cunduit',\n",
       " 'fu',\n",
       " 'appareillez',\n",
       " 'E',\n",
       " 'pur',\n",
       " 'Eliduc',\n",
       " 'enveiez.',\n",
       " 'A',\n",
       " 'grant',\n",
       " 'honur',\n",
       " 'fu',\n",
       " 'receüz,',\n",
       " 'Mut',\n",
       " 'par',\n",
       " 'fu',\n",
       " 'bien',\n",
       " 'al',\n",
       " 'rei',\n",
       " 'venuz.',\n",
       " 'Sun',\n",
       " 'ostel',\n",
       " 'fu',\n",
       " 'chiés',\n",
       " 'un',\n",
       " 'burgeis,',\n",
       " 'Que',\n",
       " 'mut',\n",
       " 'fu',\n",
       " 'sagë',\n",
       " 'e',\n",
       " 'curteis',\n",
       " ';',\n",
       " 'Sa',\n",
       " 'bele',\n",
       " 'chambre',\n",
       " 'encrutinee',\n",
       " 'Li',\n",
       " 'ad',\n",
       " 'li',\n",
       " 'ostes',\n",
       " 'delivree.',\n",
       " 'Eliduc',\n",
       " 'se',\n",
       " 'fist',\n",
       " 'bien',\n",
       " 'servir',\n",
       " ';',\n",
       " 'A',\n",
       " 'sun',\n",
       " 'manger',\n",
       " 'feseit',\n",
       " 'venir',\n",
       " 'Les',\n",
       " 'chevalers',\n",
       " 'mesaeisez',\n",
       " 'Quë',\n",
       " 'al',\n",
       " 'burc',\n",
       " 'erent',\n",
       " 'herbergez.',\n",
       " 'A',\n",
       " 'tuz',\n",
       " 'ses',\n",
       " 'hummes',\n",
       " 'defendi',\n",
       " 'Que',\n",
       " \"n'i\",\n",
       " 'eüst',\n",
       " 'nul',\n",
       " 'si',\n",
       " 'hardi',\n",
       " 'Que',\n",
       " 'des',\n",
       " 'quarante',\n",
       " 'jurs',\n",
       " 'primers',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Ppreïst',\n",
       " 'livreisun',\n",
       " 'ne',\n",
       " 'deners.',\n",
       " 'Al',\n",
       " 'terz',\n",
       " 'jur',\n",
       " \"qu'il\",\n",
       " 'ot',\n",
       " 'surjurné',\n",
       " 'Li',\n",
       " 'criz',\n",
       " 'leva',\n",
       " 'en',\n",
       " 'la',\n",
       " 'cité',\n",
       " 'Que',\n",
       " 'lur',\n",
       " 'enemi',\n",
       " 'sunt',\n",
       " 'venu',\n",
       " 'E',\n",
       " 'par',\n",
       " 'la',\n",
       " 'cuntree',\n",
       " 'espandu',\n",
       " ';',\n",
       " 'Ja',\n",
       " 'vodrunt',\n",
       " 'la',\n",
       " 'vile',\n",
       " 'asaillir',\n",
       " 'E',\n",
       " 'de',\n",
       " 'si',\n",
       " 'ke',\n",
       " 'as',\n",
       " 'portes',\n",
       " 'venir.',\n",
       " 'Eliduc',\n",
       " 'ad',\n",
       " 'la',\n",
       " 'noise',\n",
       " 'oïe',\n",
       " 'De',\n",
       " 'la',\n",
       " 'gent',\n",
       " 'ki',\n",
       " 'est',\n",
       " 'esturdie.',\n",
       " 'Il',\n",
       " \"s'est\",\n",
       " 'armé,',\n",
       " 'plus',\n",
       " \"n'i\",\n",
       " 'atent,',\n",
       " 'E',\n",
       " 'si',\n",
       " 'cumpainuns',\n",
       " 'ensement.',\n",
       " 'Quatorze',\n",
       " 'chevalers',\n",
       " 'muntant',\n",
       " 'Ot',\n",
       " 'en',\n",
       " 'la',\n",
       " 'vile',\n",
       " 'surjurnant',\n",
       " 'Plusurs',\n",
       " 'en',\n",
       " 'i',\n",
       " 'aveit',\n",
       " 'nafrez',\n",
       " 'E',\n",
       " 'des',\n",
       " 'prisuns',\n",
       " 'i',\n",
       " 'ot',\n",
       " 'asez',\n",
       " 'Cil',\n",
       " 'virent',\n",
       " 'Eliduc',\n",
       " 'munter',\n",
       " ';',\n",
       " 'Par',\n",
       " 'les',\n",
       " 'osteus',\n",
       " 'se',\n",
       " 'vunt',\n",
       " 'armer,',\n",
       " 'Fors',\n",
       " 'de',\n",
       " 'la',\n",
       " 'porte',\n",
       " 'of',\n",
       " 'lui',\n",
       " 'eissirent,',\n",
       " 'Que',\n",
       " 'sumunse',\n",
       " \"n'i\",\n",
       " 'atendirent.',\n",
       " '\"Sire,\"',\n",
       " 'funt',\n",
       " 'il,',\n",
       " '\"od',\n",
       " 'vus',\n",
       " 'irum',\n",
       " 'E',\n",
       " 'ceo',\n",
       " 'que',\n",
       " 'vus',\n",
       " 'ferez',\n",
       " 'ferum!\"',\n",
       " 'Il',\n",
       " 'lur',\n",
       " 'respunt:',\n",
       " '\"vostre',\n",
       " 'merci!',\n",
       " 'Avreit',\n",
       " 'i',\n",
       " 'nul',\n",
       " 'de',\n",
       " 'vus',\n",
       " 'ici',\n",
       " 'Ki',\n",
       " 'maupas',\n",
       " 'u',\n",
       " 'destreit',\n",
       " 'seüst,',\n",
       " 'U',\n",
       " \"l'um\",\n",
       " 'encumbrer',\n",
       " 'les',\n",
       " 'peüst',\n",
       " '?',\n",
       " 'Si',\n",
       " 'nus',\n",
       " 'ici',\n",
       " 'les',\n",
       " 'atendums,',\n",
       " 'Peot',\n",
       " 'cel',\n",
       " 'estre,',\n",
       " 'nus',\n",
       " 'justerums',\n",
       " ';',\n",
       " 'Mes',\n",
       " 'ceo',\n",
       " \"n'ateint\",\n",
       " 'a',\n",
       " 'nul',\n",
       " 'espleit,',\n",
       " 'Ki',\n",
       " 'autre',\n",
       " 'cunseil',\n",
       " 'en',\n",
       " 'sav(r)eit.\"',\n",
       " 'Cil',\n",
       " 'li',\n",
       " 'dïent:',\n",
       " '\"sire,',\n",
       " 'par',\n",
       " 'fei,',\n",
       " 'Pres',\n",
       " 'de',\n",
       " 'cel',\n",
       " 'bois',\n",
       " 'en',\n",
       " 'cel',\n",
       " 'ristei',\n",
       " 'La',\n",
       " 'ad',\n",
       " 'une',\n",
       " 'estreite',\n",
       " 'charriere,',\n",
       " 'Par',\n",
       " 'unt',\n",
       " 'il',\n",
       " 'repeirent',\n",
       " 'ariere',\n",
       " ';',\n",
       " 'Quant',\n",
       " 'il',\n",
       " 'avrunt',\n",
       " 'fet',\n",
       " 'lur',\n",
       " 'eschec,',\n",
       " 'Si',\n",
       " 'returnerunt',\n",
       " 'par',\n",
       " 'ilec;',\n",
       " 'Desarmez',\n",
       " 'sur',\n",
       " 'lur',\n",
       " 'palefrez',\n",
       " \"S'en\",\n",
       " 'revunt',\n",
       " '(il)',\n",
       " 'soventefez,',\n",
       " 'Si',\n",
       " 'se',\n",
       " 'mettent',\n",
       " 'en',\n",
       " 'aventure',\n",
       " 'Cume',\n",
       " 'de',\n",
       " 'murir',\n",
       " 'a',\n",
       " 'dreiture\".',\n",
       " 'Bien',\n",
       " 'tost',\n",
       " 'les',\n",
       " 'purreit',\n",
       " 'damagier',\n",
       " 'E',\n",
       " 'eus',\n",
       " 'laidier',\n",
       " 'e',\n",
       " 'empeirier.',\n",
       " 'Elidus',\n",
       " 'lur',\n",
       " 'ad',\n",
       " 'dit:',\n",
       " '\"amis,',\n",
       " 'La',\n",
       " 'meie',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def splitLine(s):\n",
    "    return s.split(\" \")\n",
    "\n",
    "words = lines.flatMap(splitLine)\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o86.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/D:/Users/wariche1/Orsay/DB/tp-spark/counts already exists\r\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\r\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:289)\r\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)\r\n\tat org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:550)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6810fe56e2ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwords_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mwords_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwords_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"counts\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\spark\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36msaveAsTextFile\u001b[1;34m(self, path, compressionCodecClass)\u001b[0m\n\u001b[0;32m   1568\u001b[0m             \u001b[0mkeyed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompressionCodec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m             \u001b[0mkeyed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m     \u001b[1;31m# Pair functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\spark\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o86.saveAsTextFile.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/D:/Users/wariche1/Orsay/DB/tp-spark/counts already exists\r\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\r\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:289)\r\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\r\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)\r\n\tat org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:550)\r\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "words_count = words.map(lambda x: (x,1)).reduceByKey(lambda a, b: a + b)\n",
    "words_count.collect()\n",
    "words_count.saveAsTextFile(\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit(x):\n",
    "    return(x[1]>=8)\n",
    "\n",
    "words_count_limit = words_count.filter(lambda x: x[1]>=8)\n",
    "words_count_limit.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_limit.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('TP1').getOrCreate()\n",
    "\n",
    "df1 = spark.read.load(\"food_inspections.csv\",\n",
    "format=\"csv\",\n",
    "sep=\",\",\n",
    "inferSchema=\"true\",\n",
    "header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+---------+--------------------+---------------+--------------------+-------+-----+-----+---------------+--------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------------+---------+---------------+-------------+-----+\n",
      "|Inspection ID|            DBA Name|            AKA Name|License #|       Facility Type|           Risk|             Address|   City|State|  Zip|Inspection Date|     Inspection Type|           Results|          Violations|          Latitude|         Longitude|            Location|Historical Wards 2003-2015|Zip Codes|Community Areas|Census Tracts|Wards|\n",
      "+-------------+--------------------+--------------------+---------+--------------------+---------------+--------------------+-------+-----+-----+---------------+--------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------------+---------+---------------+-------------+-----+\n",
      "|      2313103|   TAQUERIA SIGLO XX|   TAQUERIA SIGLO XX|  1476021|          Restaurant|  Risk 1 (High)|3626 1/2 W LAWRENCE |CHICAGO|   IL|60625|     10/01/2019|             Canvass|Pass w/ Conditions|3. MANAGEMENT, FO...|41.968445246044006|-87.71941657581395|(-87.719416575813...|                      null|     null|           null|         null| null|\n",
      "|      2313124|   TAQUERIA SIGLO XX|  TAQUERUIA SIGLO XX|  2694458|          Restaurant|  Risk 1 (High)|3626 1/2 W LAWRENCE |CHICAGO|   IL|60625|     10/01/2019|             License|         Not Ready|                null|41.968445246044006|-87.71941657581395|(-87.719416575813...|                      null|     null|           null|         null| null|\n",
      "|      2313098|   MI MEXICO GROCERY|   MI MEXICO GROCERY|  1494240|       Grocery Store|Risk 2 (Medium)|     2601 W 59TH ST |CHICAGO|   IL|60629|     10/01/2019|Canvass Re-Inspec...|Pass w/ Conditions|5. PROCEDURES FOR...|41.786376343209604|-87.68877651402562|(-87.688776514025...|                      null|     null|           null|         null| null|\n",
      "|      2313139|     RAGGA'S KITCHEN|                null|  2689253|                null|   Risk 3 (Low)|   633 N CICERO AVE |CHICAGO|   IL|60644|     10/01/2019|             License|         Not Ready|                null| 41.89231802030073|-87.74556872149367|(-87.745568721493...|                      null|     null|           null|         null| null|\n",
      "|      2313119|         SHU TIN XIA|         SHU TIN XIA|  2652791|          Restaurant|   Risk 3 (Low)|2428-2436 S WALLA...|CHICAGO|   IL|60616|     10/01/2019|             License|              Fail|                null| 41.84838625123219|-87.64196007758322|(-87.641960077583...|                      null|     null|           null|         null| null|\n",
      "|      2313086|          KENNEDY HS|          KENNEDY HS|    46201|              School|  Risk 1 (High)|     6325 W 56th ST |CHICAGO|   IL|60638|     09/30/2019|Canvass Re-Inspec...|              Fail|38. INSECTS, RODE...|  41.7904279580333|-87.78037223622844|(-87.780372236228...|                      null|     null|           null|         null| null|\n",
      "|      2313090|          ROYAL DELI|          ROYAL DELI|  2115060|       Grocery Store|Risk 2 (Medium)|2001-2003 S DAMEN...|CHICAGO|   IL|60608|     09/30/2019|             Canvass|   Out of Business|                null| 41.85491131910428|-87.67577256587357|(-87.675772565873...|                      null|     null|           null|         null| null|\n",
      "|      2313087|   CAMINO A LA SALUD|   CAMINO A LA SALUD|  2694282|          Restaurant|Risk 2 (Medium)|     4237 W 63RD ST |CHICAGO|   IL|60629|     09/30/2019|             License|Pass w/ Conditions|3. MANAGEMENT, FO...| 41.77847132003681|-87.72908901430353|(-87.729089014303...|                      null|     null|           null|         null| null|\n",
      "|      2313089|METROPOLITAN FAMI...|METROPOLITAN FAMI...|  2215598|Daycare Above and...|  Risk 1 (High)|     3215 W 63RD ST |CHICAGO|   IL|60629|     09/30/2019|             License|              Pass|47. FOOD & NON-FO...|  41.7788532281178|-87.70378111914683|(-87.703781119146...|                      null|     null|           null|         null| null|\n",
      "|      2313085|MEJORA TU ESTILO ...|MEJORA TU ESTILO ...|  2483547|          Restaurant|Risk 2 (Medium)|     4237 W 63RD ST |CHICAGO|   IL|60629|     09/30/2019|Canvass Re-Inspec...|Pass w/ Conditions|3. MANAGEMENT, FO...| 41.77847132003681|-87.72908901430353|(-87.729089014303...|                      null|     null|           null|         null| null|\n",
      "|      2313010|       DUNKIN DONUTS|DUNKIN DONUTS/BAS...|  2646922|          Restaurant|Risk 2 (Medium)|    5130 N BROADWAY |CHICAGO|   IL|60640|     09/27/2019|Complaint Re-Insp...|              Pass|                null| 41.97552942425021|-87.65999237688355|(-87.659992376883...|                      null|     null|           null|         null| null|\n",
      "|      2313011|             SHOKRAN|             SHOKRAN|  1884050|          Restaurant|  Risk 1 (High)|4027 W IRVING PAR...|CHICAGO|   IL|60641|     09/27/2019|             Canvass|              Fail|3. MANAGEMENT, FO...| 41.95353192936301|-87.72833818191091|(-87.728338181910...|                      null|     null|           null|         null| null|\n",
      "|      2313049|              JAIPUR|              JAIPUR|  2694084|          Restaurant|  Risk 1 (High)|  738 W RANDOLPH ST |CHICAGO|   IL|60661|     09/27/2019|License Re-Inspec...|Pass w/ Conditions|3. MANAGEMENT, FO...| 41.88451799637232|-87.64730383120978|(-87.647303831209...|                      null|     null|           null|         null| null|\n",
      "|      2313007|METHODIST HOSPITA...|METHODIST HOSPITA...|  1069788|            Hospital|  Risk 1 (High)|  5025 N PAULINA ST |CHICAGO|   IL|60640|     09/27/2019|             Canvass|   Out of Business|                null| 41.97325400916783|-87.67099338741193|(-87.670993387411...|                      null|     null|           null|         null| null|\n",
      "|      2313060|OLIVE GARDEN ITAL...|OLIVE GARDEN ITAL...|  2288707|          Restaurant|  Risk 1 (High)| 3555 W ADDISON AVE |CHICAGO|   IL|60618|     09/27/2019|             Canvass|Pass w/ Conditions|16. FOOD-CONTACT ...|41.946397665207456| -87.7173205836907|(-87.717320583690...|                      null|     null|           null|         null| null|\n",
      "|      2313027|    NICK JR.'S GRILL|    NICK JR.'S GRILL|  1992471|          Restaurant|  Risk 1 (High)|   6856 W NORTH AVE |CHICAGO|   IL|60707|     09/27/2019|             Canvass|              Fail|5. PROCEDURES FOR...| 41.90910578560824| -87.7970900667382|(-87.797090066738...|                      null|     null|           null|         null| null|\n",
      "|      2313059|      LA BOULANGERIE|      LA BOULANGERIE|  2569339|          Restaurant|Risk 2 (Medium)|  3129 W LOGAN BLVD |CHICAGO|   IL|60647|     09/27/2019|Canvass Re-Inspec...|Pass w/ Conditions|3. MANAGEMENT, FO...|41.927864202687005| -87.7061618818839|(-87.706161881883...|                      null|     null|           null|         null| null|\n",
      "|      2313051|  IT TAKES A VILLAGE|  IT TAKES A VILLAGE|  2215925|Daycare Above and...|  Risk 1 (High)| 4020 W DIVISION ST |CHICAGO|   IL|60651|     09/27/2019|             Canvass|              Pass|47. FOOD & NON-FO...|41.902765488421124|-87.72728665446205|(-87.727286654462...|                      null|     null|           null|         null| null|\n",
      "|      2313039|   THE CHICKEN SHACK|   THE CHICKEN SHACK|  2528632|          Restaurant|Risk 2 (Medium)| 7920 S WESTERN AVE |CHICAGO|   IL|60620|     09/27/2019|Canvass Re-Inspec...|              Pass|5. PROCEDURES FOR...| 41.74947552001605|-87.68297883687882|(-87.682978836878...|                      null|     null|           null|         null| null|\n",
      "|      2313061|      LA BOULANGERIE|      LA BOULANGERIE|  2664847|          Restaurant|   Risk 3 (Low)|  3129 W LOGAN BLVD |CHICAGO|   IL|60647|     09/27/2019|License Re-Inspec...|Pass w/ Conditions|                null|41.927864202687005| -87.7061618818839|(-87.706161881883...|                      null|     null|           null|         null| null|\n",
      "+-------------+--------------------+--------------------+---------+--------------------+---------------+--------------------+-------+-----+-----+---------------+--------------------+------------------+--------------------+------------------+------------------+--------------------+--------------------------+---------+---------------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Inspection ID: integer (nullable = true)\n",
      " |-- DBA Name: string (nullable = true)\n",
      " |-- AKA Name: string (nullable = true)\n",
      " |-- License #: integer (nullable = true)\n",
      " |-- Facility Type: string (nullable = true)\n",
      " |-- Risk: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Zip: integer (nullable = true)\n",
      " |-- Inspection Date: string (nullable = true)\n",
      " |-- Inspection Type: string (nullable = true)\n",
      " |-- Results: string (nullable = true)\n",
      " |-- Violations: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Historical Wards 2003-2015: string (nullable = true)\n",
      " |-- Zip Codes: string (nullable = true)\n",
      " |-- Community Areas: string (nullable = true)\n",
      " |-- Census Tracts: string (nullable = true)\n",
      " |-- Wards: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------------------+--------------------+\n",
      "|Inspection ID|            DBA Name|           results|          Violations|\n",
      "+-------------+--------------------+------------------+--------------------+\n",
      "|      2313103|   TAQUERIA SIGLO XX|Pass w/ Conditions|3. MANAGEMENT, FO...|\n",
      "|      2313098|   MI MEXICO GROCERY|Pass w/ Conditions|5. PROCEDURES FOR...|\n",
      "|      2313086|          KENNEDY HS|              Fail|38. INSECTS, RODE...|\n",
      "|      2313087|   CAMINO A LA SALUD|Pass w/ Conditions|3. MANAGEMENT, FO...|\n",
      "|      2313089|METROPOLITAN FAMI...|              Pass|47. FOOD & NON-FO...|\n",
      "|      2313085|MEJORA TU ESTILO ...|Pass w/ Conditions|3. MANAGEMENT, FO...|\n",
      "|      2313011|             SHOKRAN|              Fail|3. MANAGEMENT, FO...|\n",
      "|      2313049|              JAIPUR|Pass w/ Conditions|3. MANAGEMENT, FO...|\n",
      "|      2313060|OLIVE GARDEN ITAL...|Pass w/ Conditions|16. FOOD-CONTACT ...|\n",
      "|      2313027|    NICK JR.'S GRILL|              Fail|5. PROCEDURES FOR...|\n",
      "|      2313059|      LA BOULANGERIE|Pass w/ Conditions|3. MANAGEMENT, FO...|\n",
      "|      2313051|  IT TAKES A VILLAGE|              Pass|47. FOOD & NON-FO...|\n",
      "|      2313039|   THE CHICKEN SHACK|              Pass|5. PROCEDURES FOR...|\n",
      "|      2313040|   IRIE JERK EXPRESS|Pass w/ Conditions|3. MANAGEMENT, FO...|\n",
      "|      2313064|      THE MAIN PIZZA|              Fail|1. PERSON IN CHAR...|\n",
      "|      2313038| LILLY BELL'S DINNER|Pass w/ Conditions|25. CONSUMER ADVI...|\n",
      "|      2313047|TAISHA BEAUTY WOR...|              Fail|5. PROCEDURES FOR...|\n",
      "|      2313054|  NICKY'S RESTAURANT|              Pass|55. PHYSICAL FACI...|\n",
      "|      2313052|FRESH START DAYCA...|              Fail|2. CITY OF CHICAG...|\n",
      "|      2313019|       DUNKIN DONUTS|Pass w/ Conditions|3. MANAGEMENT, FO...|\n",
      "+-------------+--------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspections = df1.select('Inspection ID', 'DBA Name','results', 'Violations').dropna()\n",
    "inspections.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             results|    nb|\n",
      "+--------------------+------+\n",
      "|                Pass|105187|\n",
      "|                Fail| 37451|\n",
      "|  Pass w/ Conditions| 26433|\n",
      "|     Out of Business| 16706|\n",
      "|            No Entry|  6126|\n",
      "|           Not Ready|  1828|\n",
      "|Business Not Located|    67|\n",
      "+--------------------+------+\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "'Sort ['nb DESC NULLS LAST], true\n",
      "+- Project [results#22, count#191L AS nb#194L]\n",
      "   +- Aggregate [results#22], [results#22, count(1) AS count#191L]\n",
      "      +- Relation[Inspection ID#10,DBA Name#11,AKA Name#12,License ##13,Facility Type#14,Risk#15,Address#16,City#17,State#18,Zip#19,Inspection Date#20,Inspection Type#21,Results#22,Violations#23,Latitude#24,Longitude#25,Location#26,Historical Wards 2003-2015#27,Zip Codes#28,Community Areas#29,Census Tracts#30,Wards#31] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "results: string, nb: bigint\n",
      "Sort [nb#194L DESC NULLS LAST], true\n",
      "+- Project [results#22, count#191L AS nb#194L]\n",
      "   +- Aggregate [results#22], [results#22, count(1) AS count#191L]\n",
      "      +- Relation[Inspection ID#10,DBA Name#11,AKA Name#12,License ##13,Facility Type#14,Risk#15,Address#16,City#17,State#18,Zip#19,Inspection Date#20,Inspection Type#21,Results#22,Violations#23,Latitude#24,Longitude#25,Location#26,Historical Wards 2003-2015#27,Zip Codes#28,Community Areas#29,Census Tracts#30,Wards#31] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [nb#194L DESC NULLS LAST], true\n",
      "+- Aggregate [results#22], [results#22, count(1) AS nb#194L]\n",
      "   +- Project [Results#22]\n",
      "      +- Relation[Inspection ID#10,DBA Name#11,AKA Name#12,License ##13,Facility Type#14,Risk#15,Address#16,City#17,State#18,Zip#19,Inspection Date#20,Inspection Type#21,Results#22,Violations#23,Latitude#24,Longitude#25,Location#26,Historical Wards 2003-2015#27,Zip Codes#28,Community Areas#29,Census Tracts#30,Wards#31] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) Sort [nb#194L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(nb#194L DESC NULLS LAST, 200)\n",
      "   +- *(2) HashAggregate(keys=[results#22], functions=[count(1)], output=[results#22, nb#194L])\n",
      "      +- Exchange hashpartitioning(results#22, 200)\n",
      "         +- *(1) HashAggregate(keys=[results#22], functions=[partial_count(1)], output=[results#22, count#204L])\n",
      "            +- *(1) FileScan csv [Results#22] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/D:/Users/wariche1/Orsay/DB/tp-spark/food_inspections.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Results:string>\n"
     ]
    }
   ],
   "source": [
    "# group by result default name of new column is count change it to nb\n",
    "nbre = df1.groupBy(\"results\").count().withColumnRenamed(\"count\",\"nb\").sort(desc(\"nb\"))\n",
    "nbre.show()\n",
    "nbre.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|          violations|\n",
      "+-----+--------------------+\n",
      "|  1.0|3. MANAGEMENT, FO...|\n",
      "|  1.0|5. PROCEDURES FOR...|\n",
      "|  0.0|38. INSECTS, RODE...|\n",
      "|  1.0|3. MANAGEMENT, FO...|\n",
      "|  1.0|47. FOOD & NON-FO...|\n",
      "|  1.0|3. MANAGEMENT, FO...|\n",
      "|  0.0|3. MANAGEMENT, FO...|\n",
      "|  1.0|3. MANAGEMENT, FO...|\n",
      "|  1.0|16. FOOD-CONTACT ...|\n",
      "|  0.0|5. PROCEDURES FOR...|\n",
      "|  1.0|3. MANAGEMENT, FO...|\n",
      "|  1.0|47. FOOD & NON-FO...|\n",
      "|  1.0|5. PROCEDURES FOR...|\n",
      "|  1.0|3. MANAGEMENT, FO...|\n",
      "|  0.0|1. PERSON IN CHAR...|\n",
      "|  1.0|25. CONSUMER ADVI...|\n",
      "|  0.0|5. PROCEDURES FOR...|\n",
      "|  1.0|55. PHYSICAL FACI...|\n",
      "|  0.0|2. CITY OF CHICAG...|\n",
      "|  1.0|3. MANAGEMENT, FO...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def labelForResults(s):\n",
    "    if s == 'Fail':\n",
    "        return 0.0\n",
    "    elif s == 'Pass w/ Conditions' or s == 'Pass':\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "# udf is used to add a column, here the new coloumn represent the result in term of 0,1,-1\n",
    "# New column type is Double\n",
    "monudf = udf(labelForResults, DoubleType())\n",
    "\n",
    "# Select the new column that represent the label(y) and violations column.\n",
    "# Remove all lines with incorect label.\n",
    "labeledData = inspections.select(monudf(inspections[\"results\"]).alias('label'),\"violations\").where('label >= 0')\n",
    "labeledData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 2 set one for training, one for validation\n",
    "splitdf = labeledData.randomSplit([0.25, 0.75],105)\n",
    "training = splitdf[0]\n",
    "validationDf = splitdf[1]\n",
    "\n",
    "# Default regex for Tokenizer is \"\\\\s+\" separator == one or more white space\n",
    "# That not action it is just a transformation, that taking an input column \"violations\" and return a output column \"features\"\n",
    "tokenizer = Tokenizer(inputCol=\"violations\", outputCol=\"words\")\n",
    "# hashingTF generate the term frequency vectors used as vector\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'violations',\n",
       " 'words',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the pipeline with 3 transformtaions\n",
    "# lr have as input the features generated by HashingTF\n",
    "# label should be used as y ? or unsupervized\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "# Use that pipeline as model ans fit it with traning data\n",
    "# label column is taken as result in linear regression ?????\n",
    "model = pipeline.fit(training)\n",
    "\n",
    "predictionsDf = model.transform(validationDf)\n",
    "predictionsDf.registerTempTable('Predictions')\n",
    "predictionsDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|          violations|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1836,301...|[-2.1591080693880...|[0.10348317052876...|       1.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2325,408...|[0.88409148568461...|[0.70766935941174...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1225,254...|[-0.9173814313511...|[0.28549174601861...|       1.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[910,2083...|[-0.9838001906752...|[0.27213839388719...|       1.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1536,408...|[7.61759752498863...|[0.99950851990904...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1836,208...|[0.86062298693145...|[0.70279079773355...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2325,408...|[3.12561120684172...|[0.95793690681847...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[4089,417...|[10.5285079272918...|[0.99997323819007...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1536,211...|[5.81661703591097...|[0.99703117869785...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[4089,462...|[10.3287372651045...|[0.99996732074041...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[3451,408...|[6.95585543990720...|[0.99904786909214...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2083,271...|[0.87830646249017...|[0.70647115563254...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1174,153...|[12.7811907651240...|[0.99999718681588...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[3005,408...|[5.85277937133969...|[0.99713631826257...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1536,183...|[2.59019598227857...|[0.93022793821434...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[3672,408...|[0.03634534541783...|[0.50908533624439...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2083,361...|[3.69486507827723...|[0.97575178143399...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1174,345...|[12.7649771926665...|[0.99999714083247...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[3451,408...|[-2.5115352408489...|[0.07505346283122...|       1.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2083,408...|[-3.0276301706162...|[0.04619312789651...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- violations: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDf.show()\n",
    "predictionsDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|          violations|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2325,408...|[0.88409148568461...|[0.70766935941174...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1536,408...|[7.61759752498863...|[0.99950851990904...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1836,208...|[0.86062298693145...|[0.70279079773355...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2325,408...|[3.12561120684172...|[0.95793690681847...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[4089,417...|[10.5285079272918...|[0.99997323819007...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1536,211...|[5.81661703591097...|[0.99703117869785...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[4089,462...|[10.3287372651045...|[0.99996732074041...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[3451,408...|[6.95585543990720...|[0.99904786909214...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2083,271...|[0.87830646249017...|[0.70647115563254...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1174,153...|[12.7811907651240...|[0.99999718681588...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[3005,408...|[5.85277937133969...|[0.99713631826257...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1536,183...|[2.59019598227857...|[0.93022793821434...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[3672,408...|[0.03634534541783...|[0.50908533624439...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2083,361...|[3.69486507827723...|[0.97575178143399...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1174,345...|[12.7649771926665...|[0.99999714083247...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[523,619,...|[1.10470894058884...|[0.75114137905210...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[2083,306...|[2.05650921926147...|[0.88660368859989...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1957,208...|[3.27880307371521...|[0.96369442942996...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[1501,309...|[12.2747846847626...|[0.99999533204438...|       0.0|\n",
      "|  0.0|1. PERSON IN CHAR...|[1., person, in, ...|(262144,[4089,444...|[4.15427989587569...|[0.98454550008493...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "successes = predictionsDf.where(\"\"\"(prediction = 0 AND results = 'Fail') OR \n",
    "(prediction = 1 AND (results = 'Pass' OR results = 'Pass w/ Conditions'))\"\"\")\n",
    "\n",
    "successes = predictionsDf.where(\"\"\"(prediction = 0 AND label = 0) OR \n",
    "(prediction = 1 AND label = 1)\"\"\")\n",
    "\n",
    "numSuccesses = successes.count()\n",
    "\n",
    "successes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 106683 inspections and there were 98579 successful predictions\n",
      "This is a 92.40366318907417% success rate\n"
     ]
    }
   ],
   "source": [
    "numInspections = predictionsDf.count()\n",
    "print(\"There were\", numInspections, \"inspections and there were\", numSuccesses, \"successful predictions\")\n",
    "print(\"This is a\", str((float(numSuccesses) / float(numInspections)) * 100) + \"%\", \"success rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
