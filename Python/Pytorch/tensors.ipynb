{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors - the atoms of machine learning\n",
    "\n",
    "### Representation of input data\n",
    "\n",
    "- 2D matrix $\\mathbf{X}$  of $\\mathbb{R}^{m \\times n}$ \n",
    "    - Rows = m samples\n",
    "    - Columns = n features\n",
    "\n",
    "$$\\mathbf{X} = \\begin{bmatrix}\n",
    "    x_{1}^{(1)} & x_{2}^{(1)} & x_{3}^{(1)}  & \\dots & x_{n}^{(1)} \\\\\n",
    "    x_{1}^{(2)} & x_{2}^{(2)} & x_{3}^{(2)}  & \\dots & x_{n}^{(2)} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{1}^{(m)} & x_{2}^{(m)} & x_{3}^{(m)}  & \\dots & x_{n}^{(m)}\n",
    "\\end{bmatrix}.$$\n",
    "\n",
    "### Representation of model parameters\n",
    "\n",
    "- model : $$\\mathbf{\\hat{Y}} = \\mathbf{X}.\\mathbf{W}$$\n",
    "\n",
    "- 2D matrix $\\mathbf{W}$ of $\\mathbb{R}^{m \\times k}$ \n",
    "    - Rows = n parameters for the n features\n",
    "    - Columns = k predictions\n",
    "\n",
    "$$\\mathbf{W} = \\begin{bmatrix}\n",
    "    w_{1}^{(1)} & w_{2}^{(1)} & w_{3}^{(1)}  & \\dots & w_{k}^{(1)} \\\\\n",
    "    w_{1}^{(2)} & w_{2}^{(2)} & w_{3}^{(2)}  & \\dots & w_{k}^{(2)} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    w_{1}^{(n)} & w_{2}^{(n)} & w_{3}^{(n)}  & \\dots & w_{k}^{(n)}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "### Representation of output predictions\n",
    "\n",
    "- 2D matrix $\\mathbf{\\hat{Y}}$ of $\\mathbb{R}^{m \\times k}$ \n",
    "    - Rows = m labels\n",
    "    - Columns = k predictions\n",
    "\n",
    "$$\\mathbf{\\hat{Y}} = \\begin{bmatrix}\n",
    "    y_{1}^{(1)} & y_{2}^{(1)} & y_{3}^{(1)} & \\dots & y_{k}^{(1)} \\\\\n",
    "    y_{1}^{(2)} & y_{2}^{(2)} & y_{3}^{(2)} & \\dots & y_{k}^{(2)} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "    y_{1}^{(m)} & y_{2}^{(m)} & y_{3}^{(m)} & \\dots & y_{k}^{(m)}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "### PyTorch tensors\n",
    "\n",
    "- Represents data and model\n",
    "\n",
    "Conceptually identical to numpy array but:\n",
    "- Can be compute on GPUs to accelerate their numeric computations\n",
    "- Keep track of local computational graph operations and gradients of loss (next section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors and numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import multi_dot as mdot\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy\n",
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05171524, 0.16619127, 0.85743527],\n",
       "       [0.39318348, 0.67743555, 0.22306779],\n",
       "       [0.43898895, 0.27952786, 0.19438591],\n",
       "       [0.10396969, 0.0915456 , 0.65658477],\n",
       "       [0.57974962, 0.8014285 , 0.63356562]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy\n",
    "A = np.random.random((5, 3))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4562, 0.3881, 0.6899],\n",
       "        [0.4360, 0.4203, 0.3144],\n",
       "        [0.6204, 0.0700, 0.3056],\n",
       "        [0.9660, 0.7672, 0.2256],\n",
       "        [0.5234, 0.6531, 0.9459]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch\n",
    "B = torch.rand((5, 3))\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69689833, 0.87180656, 0.65295664],\n",
       "       [0.87180656, 1.21534252, 0.91581357],\n",
       "       [0.65295664, 0.91581357, 1.6552493 ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy\n",
    "A.T @ A # same as np.dot(A.T, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9902, 1.4866, 1.3545],\n",
       "        [1.4866, 1.3472, 1.2121],\n",
       "        [1.3545, 1.2121, 1.6139]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch\n",
    "B.t() @ B # same as torch.mm(B.t(), B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13.98497154, -10.07543637,   0.05778065],\n",
       "       [-10.07543637,   8.66997028,  -0.82238573],\n",
       "       [  0.05778065,  -0.82238573,   1.03635371]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy\n",
    "inv(A.T @ A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8639, -3.0768, -0.0928],\n",
       "        [-3.0768,  5.5946, -1.6195],\n",
       "        [-0.0928, -1.6195,  1.9138]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch\n",
    "torch.inverse(B.t() @ B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little more on PyTorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 1.],\n",
       "        [1., 2., 1.],\n",
       "        [1., 1., 2.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.eye(3)\n",
    "x.add(1) # Operations are also available as methods. Same as x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # x is not modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 1.],\n",
       "        [1., 2., 1.],\n",
       "        [1., 1., 2.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.add_(1) \n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _. \n",
    "# For example: x.copy_(y), x.t_(), will change x.\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  0.,  0.],\n",
       "        [ 0., 10.,  0.],\n",
       "        [ 0.,  0., 10.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.eye(3)\n",
    "y = torch.eye(3) * 10\n",
    "# x.copy(y)\n",
    "x.copy_(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2126, -1.1050, -0.4007]])\n",
      "tensor([[-0.0779, -0.7310,  0.0293],\n",
      "        [ 0.7298,  1.2243, -0.3148]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2126, -1.1050, -0.4007],\n",
       "        [-0.0779, -0.7310,  0.0293],\n",
       "        [ 0.7298,  1.2243, -0.3148]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default, it concatenates along the first axis (concatenates rows)\n",
    "x = torch.randn(1, 3)\n",
    "y = torch.randn(2, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "z = torch.cat([x, y])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6222],\n",
      "        [ 2.8865]])\n",
      "tensor([[ 2.3767, -0.5537],\n",
      "        [ 0.4160,  1.1959]])\n",
      "tensor([[-0.6222,  2.3767, -0.5537],\n",
      "        [ 2.8865,  0.4160,  1.1959]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate columns:\n",
    "x = torch.randn(2, 1)\n",
    "y = torch.randn(2, 2)\n",
    "print(x)\n",
    "print(y)\n",
    "# second arg specifies which axis to concat along\n",
    "z = torch.cat([x, y], 1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0816, 0.2577, 0.7760],\n",
       "        [0.3333, 0.2221, 0.5775],\n",
       "        [0.1140, 0.5851, 0.2798],\n",
       "        [0.0575, 0.4447, 0.7491]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0816)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0] # Access to elemment (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0816, 0.2577, 0.7760])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # Access the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0816, 0.2577, 0.7760],\n",
       "        [0.3333, 0.2221, 0.5775]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2] # Access to the first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, 0:2] # Access to all the rows and the first two columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the .view() method to reshape a tensor. \n",
    "\n",
    "This method is very usefull, because many neural network components \n",
    "expect their inputs to have a certain shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2028, -0.6602, -0.7507, -0.5043],\n",
       "         [ 2.0428,  0.0962,  0.3422, -0.0451],\n",
       "         [ 1.4442,  0.4766,  0.6738,  2.0606]],\n",
       "\n",
       "        [[-0.2790,  1.0957,  2.2131, -1.0098],\n",
       "         [ 0.6771, -1.0460,  0.7044,  0.7722],\n",
       "         [-0.2685,  0.4074, -0.7081, -0.6265]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2028, -0.6602, -0.7507, -0.5043,  2.0428,  0.0962,  0.3422, -0.0451,\n",
       "          1.4442,  0.4766,  0.6738,  2.0606],\n",
       "        [-0.2790,  1.0957,  2.2131, -1.0098,  0.6771, -1.0460,  0.7044,  0.7722,\n",
       "         -0.2685,  0.4074, -0.7081, -0.6265]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2, 12) # Reshape to 2 rows, 12 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2028, -0.6602, -0.7507, -0.5043,  2.0428,  0.0962,  0.3422, -0.0451,\n",
       "          1.4442,  0.4766,  0.6738,  2.0606],\n",
       "        [-0.2790,  1.0957,  2.2131, -1.0098,  0.6771, -1.0460,  0.7044,  0.7722,\n",
       "         -0.2685,  0.4074, -0.7081, -0.6265]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as above.  If one of the dimensions is -1, its size can be inferred\n",
    "x.view(2, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.eye(3)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch --> numpy\n",
    "A = B.numpy() \n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0,0] = 0. # A and B have the same reference for the array\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy --> torch\n",
    "A = np.eye(3)\n",
    "B = torch.from_numpy(A)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move tensors to GPU with cuda package\n",
    "\n",
    "If you have a GPU make sure that the right pytorch is installed\n",
    "\n",
    "```\n",
    "conda install pytorch torchvision cuda91 -c pytorch\n",
    "```\n",
    "Check https://pytorch.org/ for details.\n",
    "\n",
    "cuda package adds support for CUDA tensor types, that implement the same function as CPU tensors, but they utilize GPUs for computation.\n",
    "\n",
    "See : https://pytorch.org/docs/stable/cuda.html?highlight=cuda#module-torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-5b8a3d115729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         raise RuntimeError(\n\u001b[1;32m    160\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() \n",
    "                      else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move the tensor to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(5,3)\n",
    "w.to(device) # Move the tensor to device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap - what we learned so far\n",
    "\n",
    "- Tensors represents data, model parameters and predictions\n",
    "- Tensors pretty much like numpy arrays\n",
    "- Tensors operations can be compute on GPU's to accelerate computation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
